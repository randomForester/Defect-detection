{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1336\n",
      "-rw-r--r--  1 cesare.chung  staff  188157 10 10 22:27 UNET_Mura2.ipynb\n",
      "-rw-r--r--@ 1 cesare.chung  staff    1914  9 30 21:54 UNET_Mura2.py\n",
      "-rw-r--r--  1 cesare.chung  staff  467141 10 10 21:51 UNET_test.ipynb\n",
      "-rw-r--r--@ 1 cesare.chung  staff    1291  9 30 12:23 UNET_test.py\n",
      "-rw-r--r--  1 cesare.chung  staff   10577 10 28 17:44 UNET_tf.ipynb\n",
      "-rw-r--r--@ 1 cesare.chung  staff     644 10  5 12:01 UNET_tf.py\n",
      "drwxr-xr-x  4 cesare.chung  staff     136 10 10 21:58 \u001b[34mcache\u001b[m\u001b[m\n",
      "drwxr-xr-x  4 cesare.chung  staff     136 10 12 23:01 \u001b[34mdocs\u001b[m\u001b[m\n",
      "drwxr-xr-x  6 cesare.chung  staff     204 10 28 17:27 \u001b[34mprediction\u001b[m\u001b[m\n",
      "drwxr-xr-x  7 cesare.chung  staff     238 10 10 21:49 \u001b[34munet_trained\u001b[m\u001b[m\n",
      "/Users/cesare.chung/int/01_CODE_UNET/tf_UNET_test/github\n"
     ]
    }
   ],
   "source": [
    "#!gunzip THiggs.tar.gz\n",
    "#!tar -xvf THiggs.tar\n",
    "#!latex thesis2010.tex\n",
    "#!dvips thesis2010.dvi\n",
    "#!gv thesis2010.ps\n",
    "#!rm Untitled.ipynb\n",
    "#!cp /Users/cesare.chung/Dropbox/Physics/MAC-Usedcodes/THiggs.tar.gz .\n",
    "!ls -l\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tf_unet import unet, util, image_util\n",
    "import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-10-28 17:46:03,118 Layers 3, features 64, filter size 3x3, pool size: 2x2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files used: 1\n"
     ]
    }
   ],
   "source": [
    "#preparing data loading\n",
    "\n",
    "#data_provider = image_util.ImageDataProvider(\"/Users/cesare.chung/int/01_CODE_UNET/NEW/example/*.tif\",data_suffix=\".tif\",mask_suffix=\"_mask.tif\")\n",
    "data_provider = image_util.ImageDataProvider(\"/Users/cesare.chung/int/01_CODE_UNET/NEW/example/*.tif\",data_suffix=\"_img.tif\",mask_suffix=\"_mask.tif\")\n",
    "data_provider.n_class = 2\n",
    "\n",
    "#setup & training\n",
    "\n",
    "net = unet.Unet(layers=3, features_root=64, channels=3, n_class=2)\n",
    "\n",
    "#trainer = unet.Trainer(net)\n",
    "trainer = unet.Trainer(net, optimizer=\"adam\")\n",
    "\n",
    "\n",
    "z,y=data_provider(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-10-28 17:46:16,604 Removing '/Users/cesare.chung/int/01_CODE_UNET/tf_UNET_test/github/prediction'\n",
      "2017-10-28 17:46:16,606 Removing '/Users/cesare.chung/int/01_CODE_UNET/doc'\n",
      "2017-10-28 17:46:16,611 Allocating '/Users/cesare.chung/int/01_CODE_UNET/tf_UNET_test/github/prediction'\n",
      "2017-10-28 17:46:16,613 Allocating '/Users/cesare.chung/int/01_CODE_UNET/doc'\n",
      "2017-10-28 17:46:21,154 Verification error= 49.8%, loss= 0.6973\n",
      "2017-10-28 17:46:25,996 Start optimization\n",
      "2017-10-28 17:46:28,596 Iter 0, Minibatch Loss= 0.5732, Training Accuracy= 0.9411, Minibatch error= 5.9%\n",
      "2017-10-28 17:46:30,864 Iter 1, Minibatch Loss= 0.3226, Training Accuracy= 0.9411, Minibatch error= 5.9%\n",
      "2017-10-28 17:46:32,912 Iter 2, Minibatch Loss= 0.5210, Training Accuracy= 0.9411, Minibatch error= 5.9%\n",
      "2017-10-28 17:46:35,003 Iter 3, Minibatch Loss= 0.2217, Training Accuracy= 0.9411, Minibatch error= 5.9%\n",
      "2017-10-28 17:46:37,068 Iter 4, Minibatch Loss= 0.3526, Training Accuracy= 0.9411, Minibatch error= 5.9%\n",
      "2017-10-28 17:46:39,005 Iter 5, Minibatch Loss= 0.4275, Training Accuracy= 0.9411, Minibatch error= 5.9%\n",
      "2017-10-28 17:46:40,983 Iter 6, Minibatch Loss= 0.4473, Training Accuracy= 0.9411, Minibatch error= 5.9%\n",
      "2017-10-28 17:46:43,096 Iter 7, Minibatch Loss= 0.4435, Training Accuracy= 0.9411, Minibatch error= 5.9%\n",
      "2017-10-28 17:46:45,047 Iter 8, Minibatch Loss= 0.4256, Training Accuracy= 0.9411, Minibatch error= 5.9%\n",
      "2017-10-28 17:46:47,080 Iter 9, Minibatch Loss= 0.3963, Training Accuracy= 0.9411, Minibatch error= 5.9%\n",
      "2017-10-28 17:46:49,068 Iter 10, Minibatch Loss= 0.3586, Training Accuracy= 0.9411, Minibatch error= 5.9%\n",
      "2017-10-28 17:46:51,012 Iter 11, Minibatch Loss= 0.3157, Training Accuracy= 0.9411, Minibatch error= 5.9%\n",
      "2017-10-28 17:46:52,936 Iter 12, Minibatch Loss= 0.2733, Training Accuracy= 0.9411, Minibatch error= 5.9%\n",
      "2017-10-28 17:46:54,863 Iter 13, Minibatch Loss= 0.2390, Training Accuracy= 0.9411, Minibatch error= 5.9%\n",
      "2017-10-28 17:46:56,789 Iter 14, Minibatch Loss= 0.2189, Training Accuracy= 0.9411, Minibatch error= 5.9%\n",
      "2017-10-28 17:46:58,971 Iter 15, Minibatch Loss= 0.2155, Training Accuracy= 0.9411, Minibatch error= 5.9%\n",
      "2017-10-28 17:46:58,972 Epoch 0, Average loss: 0.4170, learning rate: 0.0010\n",
      "2017-10-28 17:47:02,145 Verification error= 5.9%, loss= 0.2155\n",
      "2017-10-28 17:47:07,872 Iter 16, Minibatch Loss= 0.2247, Training Accuracy= 0.9411, Minibatch error= 5.9%\n",
      "2017-10-28 17:47:09,838 Iter 17, Minibatch Loss= 0.2379, Training Accuracy= 0.9411, Minibatch error= 5.9%\n",
      "2017-10-28 17:47:11,921 Iter 18, Minibatch Loss= 0.2480, Training Accuracy= 0.9411, Minibatch error= 5.9%\n",
      "2017-10-28 17:47:13,868 Iter 19, Minibatch Loss= 0.2514, Training Accuracy= 0.9411, Minibatch error= 5.9%\n",
      "2017-10-28 17:47:16,143 Iter 20, Minibatch Loss= 0.2485, Training Accuracy= 0.9411, Minibatch error= 5.9%\n",
      "2017-10-28 17:47:18,331 Iter 21, Minibatch Loss= 0.2408, Training Accuracy= 0.9411, Minibatch error= 5.9%\n",
      "2017-10-28 17:47:20,540 Iter 22, Minibatch Loss= 0.2311, Training Accuracy= 0.9411, Minibatch error= 5.9%\n",
      "2017-10-28 17:47:22,951 Iter 23, Minibatch Loss= 0.2223, Training Accuracy= 0.9411, Minibatch error= 5.9%\n",
      "2017-10-28 17:47:25,126 Iter 24, Minibatch Loss= 0.2165, Training Accuracy= 0.9411, Minibatch error= 5.9%\n",
      "2017-10-28 17:47:27,054 Iter 25, Minibatch Loss= 0.2145, Training Accuracy= 0.9411, Minibatch error= 5.9%\n",
      "2017-10-28 17:47:28,981 Iter 26, Minibatch Loss= 0.2162, Training Accuracy= 0.9411, Minibatch error= 5.9%\n",
      "2017-10-28 17:47:30,897 Iter 27, Minibatch Loss= 0.2204, Training Accuracy= 0.9411, Minibatch error= 5.9%\n",
      "2017-10-28 17:47:32,827 Iter 28, Minibatch Loss= 0.2254, Training Accuracy= 0.9411, Minibatch error= 5.9%\n",
      "2017-10-28 17:47:34,745 Iter 29, Minibatch Loss= 0.2295, Training Accuracy= 0.9411, Minibatch error= 5.9%\n",
      "2017-10-28 17:47:36,676 Iter 30, Minibatch Loss= 0.2319, Training Accuracy= 0.9411, Minibatch error= 5.9%\n",
      "2017-10-28 17:47:38,612 Iter 31, Minibatch Loss= 0.2321, Training Accuracy= 0.9411, Minibatch error= 5.9%\n",
      "2017-10-28 17:47:38,613 Epoch 1, Average loss: 0.2390, learning rate: 0.0010\n",
      "2017-10-28 17:47:41,244 Verification error= 5.9%, loss= 0.2321\n",
      "2017-10-28 17:47:46,724 Iter 32, Minibatch Loss= 0.2303, Training Accuracy= 0.9411, Minibatch error= 5.9%\n",
      "2017-10-28 17:47:48,724 Iter 33, Minibatch Loss= 0.2269, Training Accuracy= 0.9411, Minibatch error= 5.9%\n",
      "2017-10-28 17:47:50,654 Iter 34, Minibatch Loss= 0.2228, Training Accuracy= 0.9411, Minibatch error= 5.9%\n",
      "2017-10-28 17:47:52,563 Iter 35, Minibatch Loss= 0.2189, Training Accuracy= 0.9411, Minibatch error= 5.9%\n",
      "2017-10-28 17:47:54,514 Iter 36, Minibatch Loss= 0.2159, Training Accuracy= 0.9411, Minibatch error= 5.9%\n",
      "2017-10-28 17:47:56,464 Iter 37, Minibatch Loss= 0.2143, Training Accuracy= 0.9411, Minibatch error= 5.9%\n",
      "2017-10-28 17:47:58,533 Iter 38, Minibatch Loss= 0.2139, Training Accuracy= 0.9411, Minibatch error= 5.9%\n",
      "2017-10-28 17:48:00,593 Iter 39, Minibatch Loss= 0.2142, Training Accuracy= 0.9411, Minibatch error= 5.9%\n",
      "2017-10-28 17:48:02,609 Iter 40, Minibatch Loss= 0.2149, Training Accuracy= 0.9411, Minibatch error= 5.9%\n",
      "2017-10-28 17:48:04,679 Iter 41, Minibatch Loss= 0.2154, Training Accuracy= 0.9411, Minibatch error= 5.9%\n",
      "2017-10-28 17:48:06,836 Iter 42, Minibatch Loss= 0.2155, Training Accuracy= 0.9411, Minibatch error= 5.9%\n",
      "2017-10-28 17:48:08,886 Iter 43, Minibatch Loss= 0.2152, Training Accuracy= 0.9411, Minibatch error= 5.9%\n",
      "2017-10-28 17:48:11,120 Iter 44, Minibatch Loss= 0.2146, Training Accuracy= 0.9411, Minibatch error= 5.9%\n",
      "2017-10-28 17:48:13,152 Iter 45, Minibatch Loss= 0.2139, Training Accuracy= 0.9411, Minibatch error= 5.9%\n",
      "2017-10-28 17:48:15,092 Iter 46, Minibatch Loss= 0.2135, Training Accuracy= 0.9411, Minibatch error= 5.9%\n",
      "2017-10-28 17:48:17,216 Iter 47, Minibatch Loss= 0.2133, Training Accuracy= 0.9411, Minibatch error= 5.9%\n",
      "2017-10-28 17:48:17,217 Epoch 2, Average loss: 0.2237, learning rate: 0.0010\n",
      "2017-10-28 17:48:19,830 Verification error= 5.9%, loss= 0.2133\n",
      "2017-10-28 17:48:24,312 Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "output_path = '/Users/cesare.chung/int/01_CODE_UNET/doc'\n",
    "\n",
    "#path = trainer.train(data_provider, output_path, training_iters=32, epochs=100)\n",
    "\n",
    "path = trainer.train(data_provider, output_path, training_iters=16, epochs=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
